llm:
  api_type: 'ollama' # or azure / ollama / groq etc. Check LLMType for more options
  model: 'llama3' # or gpt-3.5-turbo
  base_url: 'http://127.0.0.1:11434/api' # or forward url / other llm url
  api_key: 'ollama'
  # proxy: 'YOUR_LLM_PROXY_IF_NEEDED' # Optional. If you want to use a proxy, set it here.
  # pricing_plan: 'YOUR_PRICING_PLAN' # Optional. If your pricing plan uses a different name than the `model`.
